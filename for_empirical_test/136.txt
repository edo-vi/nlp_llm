
Hatnote group




File:Turing test diagrampng

The Turing test originally called the imitation game by Alan Turing in 1950 If the evaluator could not reliably tell the machine from the human the machine would be said to have passed the test The test results would not depend on the machines ability to give correct question answering
The test was introduced by Turing in his 1950 paper "Computing Machinery and Intelligence" while working at the University of Manchester It opens with the words: "I propose to consider the question Can machines think? Because "thinking" is difficult to define Turing chooses to "replace the question by another which is closely related to it and is expressed in relatively unambiguous words" Turing describes the new form of the problem in terms of a threeperson game called the "imitation game" in which an interrogator asks questions of a man and a woman in another room in order to determine the correct sex of the two players Turings new question is: "Are there imaginable digital computers which would do well in the imitation game?" This question Turing believed was one that could actually be answered In the remainder of the paper he argued against all the major objections to the proposition that "machines can think"

Since Turing introduced his test it has been both highly influential and widely criticised and has become an important concept in the philosophy of artificial intelligence Some of its criticisms such as John Searles Chinese room are themselves controversial

 History 

 Philosophical background 

The question of whether it is possible for machines to think has a long history which is firmly entrenched in the distinction between dualism (philosophy of mind)Here Descartes notes that automata are capable of responding to human interactions but argues that such automata cannot respond appropriately to things said in their presence in the way that any human can Descartes therefore prefigures the Turing test by defining the insufficiency of appropriate linguistic response as that which separates the human from the automaton Descartes fails to consider the possibility that future automata might be able to overcome such insufficiency and so does not propose the Turing test as such even if he prefigures its conceptual framework and criterion

Denis Diderot formulates in his 1746 book Philosophical Thoughts


This does not mean he agrees with this but that it was already a common argument of materialists at that time

According to dualism the mind is nonphysical entity
In 1936 philosopher Alfred Ayer considered the standard philosophical question of other minds problem
 Cultural background 
Tests where a human judges whether a computer or an alien is intelligent were an established convention in science fiction by the 1940s and it is likely that Turing would have been aware of these Stanley G Weinbaums "A Martian Odyssey" (1934) provides an example of how nuanced such tests could be

Earlier examples of machines or automatons attempting to pass as human include the Ancient Greek myth of Pygmalion (mythology)
 Alan Turing and the Imitation Game 

Researchers in the United Kingdom had been exploring "machine intelligence" for up to ten years prior to the founding of the field of artificial intelligence (Artificial intelligence
Turing in particular had been running the notion of machine intelligence since at least 1941 and one of the earliestknown mentions of "computer intelligence" was made by him in 1947 In Turings report "Intelligent Machinery"<ref>
 

</ref> he investigated "the question of whether or not it is possible for machinery to show intelligent behaviour" and as part of that investigation proposed what may be considered the forerunner to his later tests:
<blockquote>It is not difficult to devise a paper machine which will play a not very bad game of chess Now get three men A B and C as subjects for the experiment A and C are to be rather poor chess players B is the operator who works the paper machine  Two rooms are used with some arrangement for communicating moves and a game is played between C and either A or the paper machine C may find it quite difficult to tell which he is playing</blockquote>

"Computing Machinery and Intelligence" (
To demonstrate this approach Turing proposes a test inspired by a party game known as the "imitation game" in which a man and a woman go into separate rooms and guests try to tell them apart by writing a series of questions and reading the typewritten answers sent back In this game both the man and the woman aim to convince the guests that they are the other (Huma Shah argues that this twohuman version of the game was presented by Turing only to introduce the reader to the machinehuman questionanswer test) Turing described his new version of the game as follows:

<blockquote>We now ask the question "What will happen when a machine takes the part of A in this game?" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original "Can machines think?"</blockquote>

Later in the paper Turing suggests an "equivalent" alternative formulation involving a judge conversing only with a computer and a man While neither of these formulations precisely matches the version of the Turing test that is more generally known today he proposed a third in 1952 In this version which Turing discussed in a BBC radio broadcast a jury asks questions of a computer and the role of the computer is to make a significant proportion of the jury believe that it is really a man

Turings paper considered nine putative objections which include some of the major arguments against artificial intelligence that have been raised in the years since the paper was published (see "Computing Machinery and Intelligence")

 ELIZA and PARRY 

In 1966 Joseph Weizenbaum created a program which appeared to pass the Turing test The program known as ELIZA worked by examining a users typed comments for keywords If a keyword is found a rule that transforms the users comments is applied and the resulting sentence is returned If a keyword is not found ELIZA responds either with a generic riposte or by repeating one of the earlier comments In addition Weizenbaum developed ELIZA to replicate the behaviour of a personcentered psychotherapy
Kenneth Colby created PARRY in 1972 a program described as "ELIZA with attitude" It attempted to model the behaviour of a paranoia
In the 21st century versions of these programs (now known as "chatbots") continue to fool people "CyberLover" a malware program preys on Internet users by convincing them to "reveal information about their identities or to lead them to visit a web site that will deliver malicious content to their computers" The program has emerged as a "Valentinerisk" flirting with people "seeking relationships online in order to collect their personal data"

 The Chinese room 


John Searles 1980 paper Minds Brains and Programs proposed the "Chinese room" thought experiment and argued that the Turing test could not be used to determine if a machine could think Searle noted that software (such as ELIZA) could pass the Turing test simply by manipulating symbols of which they had no understanding Without understanding they could not be described as "thinking" in the same sense people did Therefore Searle concluded the Turing test could not prove that machines could think Much like the Turing test itself Searles argument has been both widely criticised<ref>There are a large number of arguments against Searles Chinese room A few are:

 Citation

 Citation

       

 Citation

       
</ref> and endorsed

Arguments such as Searles and others working on the philosophy of mind sparked off a more intense debate about the nature of intelligence the possibility of machines with a conscious mind and the value of the Turing test that continued through the 1980s and 1990s

 Loebner Prize 


The Loebner Prize provides an annual platform for practical Turing tests with the first competition held in November 1991 It is underwritten by Hugh Loebner The Cambridge Center for Behavioral Studies in Massachusetts United States organised the prizes up to and including the 2003 contest As Loebner described it one reason the competition was created is to advance the state of AI research at least in part because no one had taken steps to implement the Turing test despite 40 years of discussing it

The first Loebner Prize competition in 1991 led to a renewed discussion of the viability of the Turing test and the value of pursuing it in both the popular press and academia The first contest was won by a mindless program with no identifiable intelligence that managed to fool naïve interrogators into making the wrong identification This highlighted several of the shortcomings of the Turing test (discussed Weaknesses
The silver (text only) and gold (audio and visual) prizes have never been won However the competition has awarded the bronze medal every year for the computer system that in the judges opinions demonstrates the "most human" conversational behaviour among that years entries Artificial Linguistic Internet Computer Entity (ALICE) has won the bronze award on three occasions in recent times (2000 2001 2004) Learning AI Jabberwacky won in 2005 and 2006

The Loebner Prize tests conversational intelligence; winners are typically chatterbot programs or Artificial Conversational Entity (ACE)
 Google LaMDA chatbot 

In June 2022 the Google AI
Versions<! This title is linked to by the article Computing Machinery and Intelligence >
File:The Imitation Gamesvg
Saul Traiger argues that there are at least three primary versions of the Turing test two of which are offered in "Computing Machinery and Intelligence" and one that he describes as the "Standard Interpretation" While there is some debate regarding whether the "Standard Interpretation" is that described by Turing or instead based on a misreading of his paper these three versions are not regarded as equivalent and their strengths and weaknesses are distinct

Turings original article describes a simple party game involving three players Player A is a man player B is a woman and player C (who plays the role of the interrogator) is of either gender In the imitation game player C is unable to see either player A or player B and can communicate with them only through written notes By asking questions of player A and player B player C tries to determine which of the two is the man and which is the woman Player As role is to trick the interrogator into making the wrong decision while player B attempts to assist the interrogator in making the right one

Turing then asks:

<blockquote>"What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?" These questions replace our original "Can machines think?"</blockquote>

File:Turing Test Version 1svg
The second version appeared later in Turings 1950 paper Similar to the original imitation game test the role of player A is performed by a computer However the role of player B is performed by a man rather than a woman

<blockquote>Let us fix our attention on one particular digital computer C Is it true that by modifying this computer to have an adequate storage suitably increasing its speed of action and providing it with an appropriate programme C can be made to play satisfactorily the part of A in the imitation game the part of B being taken by a man?</blockquote>

In this version both player A (the computer) and player B are trying to trick the interrogator into making an incorrect decision

The standard interpretation is not included in the original paper but is both accepted and debated
Common understanding has it that the purpose of the Turing test is not specifically to determine whether a computer is able to fool an interrogator into believing that it is a human but rather whether a computer could imitate a human While there is some dispute whether this interpretation was intended by Turing Sterrett believes that it was and thus conflates the second version with this one while others such as Traiger do not&nbsp;– this has nevertheless led to what can be viewed as the "standard interpretation" In this version player A is a computer and player B a person of either sex The role of the interrogator is not to determine which is male and which is female but which is a computer and which is a human The fundamental issue with the standard interpretation is that the interrogator cannot differentiate which responder is human and which is machine There are issues about duration but the standard interpretation generally considers this limitation as something that should be reasonable

Interpretations

Controversy has arisen over which of the alternative formulations of the test Turing intended Sterrett argues that two distinct tests can be extracted from his 1950 paper and that Pace (Latin)
According to Huma Shah Turing himself was concerned with whether a machine could think and was providing a simple method to examine this: through humanmachine questionanswer sessions Shah argues the imitation game which Turing described could be practicalized in two different ways: a) onetoone interrogatormachine test and b) simultaneous comparison of a machine with a human both questioned in parallel by an interrogator 

Still other writers have interpreted Turing as proposing that the imitation game itself is the test without specifying how to take into account Turings statement that the test that he proposed using the party version of the imitation game is based upon a criterion of comparative frequency of success in that imitation game rather than a capacity to succeed at one round of the game

Some writers argue that the imitation game is best understood by its social aspects In his 1948 paper Turing refers to intelligence as an "emotional concept" and notes that <blockquote>The extent to which we regard something as behaving in an intelligent manner is determined as much by our own state of mind and training as by the properties of the object under consideration If we are able to explain and predict its behaviour or if there seems to be little underlying plan we have little temptation to imagine intelligence With the same object therefore it is possible that one man would consider it as intelligent and another would not; the second man would have found out the rules of its behaviour</blockquote>Following this remark and similar ones scattered throughout Turings publications Diane Proudfoot claims that Turing held a responsedependence approach to intelligence according to which an intelligent (or thinking) entity is one that appears intelligent to an average interrogator Bernardo Gonçalves claims that Turing intended his test to be a thought experiment one which would supposedly cause humans to realize that machines should be considered as intelligent entities Taking up both lines Shlomo Danziger promotes a sociotechnological interpretation according to which Turing saw the imitation game not as an intelligence test but as a technological aspiration  one whose realization would likely involve a change in societys attitude toward machines According to this reading Turings celebrated 50year prediction  that by the end of the 20th century his test will be passed by some machine  actually consists of two distinguishable predictions The first is a technological prediction:<blockquote>I believe that in about fifty years time it will be possible to programme computers  to make them play the imitation game so well that an average interrogator will not have more than 70% chance of making the right identification after five minutes of questioning</blockquote>The second prediction Turing makes is a sociological one:<blockquote>I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted</blockquote>Danziger claims further that for Turing alteration of societys attitude towards machinery is a prerequisite for the existence of intelligent machines: Only when the term "intelligent machine" is no longer seen as an oxymoron the existence of intelligent machines would become logically possible

Saygin has suggested that maybe the original game is a way of proposing a less biased experimental design as it hides the participation of the computer The imitation game also includes a "social hack" not found in the standard interpretation as in the game both computer and male human are required to play as pretending to be someone they are not

 Should the interrogator know about the computer? 

A crucial piece of any laboratory test is that there should be a control Turing never makes clear whether the interrogator in his tests is aware that one of the participants is a computer He states only that player A is to be replaced with a machine not that player C is to be made aware of this replacement When Colby FD Hilf S Weber and AD Kramer tested PARRY they did so by assuming that the interrogators did not need to know that one or more of those being interviewed was a computer during the interrogation As Ayse Saygin Peter Swirski and others have highlighted this makes a big difference to the implementation and outcome of the test An experimental study looking at Paul GriceConversational Maxims
 Strengths 

 Tractability and simplicity 

The power and appeal of the Turing test derives from its simplicity The philosophy of mind psychology and modern neuroscience have been unable to provide definitions of "intelligence" and "thinking" that are sufficiently precise and general to be applied to machines Without such definitions the central questions of the philosophy of artificial intelligence cannot be answered The Turing test even if imperfect at least provides something that can actually be measured As such it is a pragmatic attempt to answer a difficult philosophical question

 Breadth of subject matter 

The format of the test allows the interrogator to give the machine a wide variety of intellectual tasks Turing wrote that "the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavour that we wish to include" John Haugeland adds that "understanding the words is not enough; you have to understand the topic as well"

To pass a welldesigned Turing test the machine must use natural language processing
The Feigenbaum test is designed to take advantage of the broad range of topics available to a Turing test It is a limited form of Turings questionanswer game which compares the machine against the abilities of experts in specific fields such as literature or chemistry IBMs Watson (artificial intelligence software)      </ref>

 Emphasis on emotional and aesthetic intelligence 

As a Cambridge honours graduate in mathematics Turing might have been expected to propose a test of computer intelligence requiring expert knowledge in some highly technical field and thus anticipating Subjectmatter expert Turing test
Given the status of human sexual dimorphism as Creation myths
: Interrogator: Will X please tell me the length of his or her hair?

: Contestant: My hair is shingled and the longest strands are about nine inches long

When Turing does introduce some specialised knowledge into one of his imagined dialogues the subject is not maths or electronics but poetry:

: Interrogator: In the first line of your sonnet which reads "Shall I compare thee to a summers day" would not "a spring day" do as well or better?

: Witness: It wouldnt scansion
: Interrogator: How about "a winters day" That would scan all right

: Witness: Yes but nobody wants to be compared to a winters day

Turing thus once again demonstrates his interest in empathy and aesthetic sensitivity as components of an artificial intelligence; and in light of an increasing awareness of the threat from an AI run amok it has been suggested that this focus perhaps represents a critical intuition on Turings part ie that emotional and aesthetic intelligence will play a key role in the creation of a "friendly AI" It is further noted however that whatever inspiration Turing might be able to lend in this direction depends upon the preservation of his original vision which is to say further that the promulgation of a "standard interpretation" of the Turing test—ie one which focuses on a discursive intelligence only—must be regarded with some caution

 Weaknesses 

Turing did not explicitly state that the Turing test could be used as a measure of "intelligence" or any other human quality He wanted to provide a clear and understandable alternative to the word "think" which he could then use to reply to criticisms of the possibility of "thinking machines" and to suggest ways that research might move forward 

Nevertheless the Turing test has been proposed as a measure of a machines "ability to think" or its "intelligence" This proposal has received criticism from both philosophers and computer scientists The interpretation makes the assumption that an interrogator can determine if a machine is "thinking" by comparing its behaviour with human behaviour Every element of this assumption has been questioned: the reliability of the interrogators judgement the value of comparing the machine with a human and the value of comparing only behaviour Because of these and other considerations some AI researchers have questioned the relevance of the test to their field

 Naïveté of interrogators 

In practice the tests results can easily be dominated not by the computers intelligence but by the attitudes skill or naïveté of the questioner Numerous experts in the field including cognitive scientist Gary Marcus insist that the Turing test only shows how easy it is to fool humans and is not an indication of machine intelligence

Turing does not specify the precise skills and knowledge required by the interrogator in his description of the test but he did use the term "average interrogator": "the average interrogator would not have more than 70 per cent chance of making the right identification after five minutes of questioning"

Chatterbot programs such as ELIZA have repeatedly fooled unsuspecting people into believing that they are communicating with human beings In these cases the "interrogators" are not even aware of the possibility that they are interacting with computers To successfully appear human there is no need for the machine to have any intelligence whatsoever and only a superficial resemblance to human behaviour is required

Early Loebner Prize competitions used "unsophisticated" interrogators who were easily fooled by the machines Since 2004 the Loebner Prize organisers have deployed philosophers computer scientists and journalists among the interrogators Nonetheless some of these experts have been deceived by the machines

One interesting feature of the Turing test is the frequency of the confederate effect when the confederate (tested) humans are misidentified by the interrogators as machines It has been suggested that what interrogators expect as human responses is not necessarily typical of humans As a result some individuals can be categorised as machines This can therefore work in favour of a competing machine The humans are instructed to "act themselves" but sometimes their answers are more like what the interrogator expects a machine to say This raises the question of how to ensure that the humans are motivated to "act human"

 Human intelligence vs intelligence in general 

File:Weakness of Turing test 1svgThe Turing test does not directly test whether the computer behaves intelligently It tests only whether the computer behaves like a human being Since human behaviour and intelligent behaviour are not exactly the same thing the test can fail to accurately measure intelligence in two ways:

; Some human behaviour is unintelligent: The Turing test requires that the machine be able to execute all human behaviours regardless of whether they are intelligent It even tests for behaviours that may not be considered intelligent at all such as the susceptibility to insults the temptation to lie or simply a high frequency of typographical error
: This objection was raised by The Economist in an article entitled "artificial stupidity" published shortly after the first Loebner Prize competition in 1992 The article noted that the first Loebner winners victory was due at least in part to its ability to "imitate human typing errors" Turing himself had suggested that programs add errors into their output so as to be better "players" of the game

; Some intelligent behaviour is inhuman: The Turing test does not test for highly intelligent behaviours such as the ability to solve difficult problems or come up with original insights In fact it specifically requires deception on the part of the machine: if the machine is more intelligent than a human being it must deliberately avoid appearing too intelligent If it were to solve a computational problem that is practically impossible for a human to solve then the interrogator would know the program is not human and the machine would fail the test

: Because it cannot measure intelligence that is beyond the ability of humans the test cannot be used to build or evaluate systems that are more intelligent than humans Because of this several test alternatives that would be able to evaluate superintelligent systems have been proposed<ref>Several alternatives to the Turing test designed to evaluate machines more intelligent than humans:
 
 
 
 
</ref>

 Consciousness vs the simulation of consciousness 


The Turing test is concerned strictly with how the subject acts&nbsp;– the external behaviour of the machine In this regard it takes a behaviourist or Functionalism (philosophy of mind)
John Searle has argued that external behaviour cannot be used to determine if a machine is "actually" thinking or merely "simulating thinking" His Chinese room argument is intended to show that even if the Turing test is a good operational definition of intelligence it may not indicate that the machine has a mind consciousness or intentionality (Intentionality is a philosophical term for the power of thoughts to be "about" something)

Turing anticipated this line of criticism in his original paper writing:  

 Impracticality and irrelevance: the Turing test and AI research 

File:Sam Harris takes the Turing Test (51169748740)png
Mainstream AI researchers argue that trying to pass the Turing test is merely a distraction from more fruitful research Indeed the Turing test is not an active focus of much academic or commercial effort—as Stuart J Russell
First there are easier ways to test their programs Most current research in AIrelated fields is aimed at modest and specific goals such as object recognition or logistics To test the intelligence of the programs that solve these problems AI researchers simply give them the task directly Stuart Russell and Peter Norvig suggest an analogy with the history of flight: Planes are tested by how well they fly not by comparing them to birds "Aeronautics
Second creating lifelike simulations of human beings is a difficult problem on its own that does not need to be solved to achieve the basic goals of AI research Believable human characters may be interesting in a work of art a video game
Turing did not intend for his idea to be used to test the intelligence of programs&mdash;he wanted to provide a clear and understandable example to aid in the discussion of the philosophy of artificial intelligence John McCarthy (computer scientist)</ref>

 The Languagecentric Objection 

Another well known objection raised towards the Turing Test concerns its exclusive focus on the linguistic behaviour (ie it is only a "languagebased" experiment while all the other cognitive faculties are not tested) This drawback downsizes the role of other modalityspecific "intelligent abilities" concerning human beings that the psychologist Howard Gardner in his "Theory of multiple intelligences
 Silence 

A critical aspect of the Turing test is that a machine must give itself away as being a machine by its utterances An interrogator must then make the "right identification" by correctly identifying the machine as being just that If however a machine remains silent during a conversation then it is not possible for an interrogator to accurately identify the machine other than by means of a calculated guess
Even taking into account a parallel/hidden human as part of the test may not help the situation as humans can often be misidentified as being a machine

 Variations 

Numerous other versions of the Turing test including those expounded above have been raised through the years

 Reverse Turing test and CAPTCHA 

A modification of the Turing test wherein the objective of one or more of the roles have been reversed between machines and humans is termed a reverse Turing test An example is implied in the work of psychoanalyst Wilfred Bion who was particularly fascinated by the "storm" that resulted from the encounter of one mind by another In his 2000 book among several other original points with regard to the Turing test literary scholar Peter Swirski discussed in detail the idea of what he termed the Swirski test—essentially the reverse Turing test He pointed out that it overcomes most if not all standard objections levelled at the standard version

Carrying this idea forward R D Hinshelwood described the mind as a "mind recognizing apparatus" The challenge would be for the computer to be able to determine if it were interacting with a human or another computer This is an extension of the original question that Turing attempted to answer but would perhaps offer a high enough standard to define a machine that could "think" in a way that we typically define as characteristically human

CAPTCHA is a form of reverse Turing test Before being allowed to perform some action on a website the user is presented with alphanumerical characters in a distorted graphic image and asked to type them out This is intended to prevent automated systems from being used to abuse the site The rationale is that software sufficiently sophisticated to read and reproduce the distorted image accurately does not exist (or is not available to the average user) so any system able to do so is likely to be a human

Software that could reverse CAPTCHA with some accuracy by analysing patterns in the generating engine started being developed soon after the creation of CAPTCHA<ref>Citation
</ref>
In 2013 researchers at Vicarious (company)</ref>
In 2014 Google engineers demonstrated a system that could defeat CAPTCHA challenges with 998% accuracy<ref>Citation
</ref>
In 2015 Shuman Ghosemajumder former click fraud czar of Google stated that there were Cybercrime</ref>

 Distinguishing accurate use of language from actual understanding 

A further variation is motivated by the concern that modern Natural Language Processing prove to be highly successful in generating text on the basis of a huge text corpus and could eventually pass the Turing test simply by manipulating words and sentences that have been used in the initial training of the model Since the interrogator has no precise understanding of the training data the model might simply be returning sentences that exist in similar fashion in the enormous amount of training data For this reason Arthur Schwaninger proposes a variation of the Turing test that can distinguish between systems that are only capable of using language and systems that understand language He proposes a test in which the machine is confronted with philosophical questions that do not depend on any prior knowledge and yet require selfreflection to be answered appropriately 

 Subject matter expert Turing test 

Another variation is described as the subjectmatter expert Turing test where a machines response cannot be distinguished from an expert in a given field This is also known as a "Feigenbaum test" and was proposed by Edward Feigenbaum in a 2003 paper

 "Lowlevel" cognition test 

Robert M French
 Total Turing test 

The "Total Turing test" variation of the Turing test proposed by cognitive scientist Stevan Harnad<ref>citation
</ref> adds two further requirements to the traditional Turing test The interrogator can also test the perceptual abilities of the subject (requiring computer vision) and the subjects ability to manipulate objects (requiring robotics)

 Electronic health records 

A letter published in Communications of the ACM describes the concept of generating a synthetic patient population and proposes a variation of Turing test to assess the difference between synthetic and real patients The letter states: "In the EHR context though a human physician can readily distinguish between synthetically generated and real live human patients could a machine be given the intelligence to make such a determination on its own?" and further the letter states: "Before synthetic patient identities become a public health problem the legitimate EHR market might benefit from applying Turing Testlike techniques to ensure greater data reliability and diagnostic value Any new techniques must thus consider patients heterogeneity and are likely to have greater complexity than the Allen eighthgradesciencetest is able to grade"

 Minimum intelligent signal test 

The minimum intelligent signal test was proposed by Chris McKinstry as "the maximum abstraction of the Turing test" in which only binary responses (true/false or yes/no) are permitted to focus only on the capacity for thought It eliminates text chat problems like Naïveté of interrogators</ref>

 Hutter Prize 

The organisers of the Hutter Prize believe that compressing natural language text is a hard AI problem equivalent to passing the Turing test

The data compression test has some advantages over most versions and variations of a Turing test including:

 It gives a single number that can be directly used to compare which of two machines is "more intelligent"
 It does not require the computer to lie to the judge

The main disadvantages of using data compression as a test are:

 It is not possible to test humans this way
 It is unknown what particular "score" on this test—if any—is equivalent to passing a humanlevel Turing test

 Other tests based on compression or Kolmogorov complexity 

A related approach to Hutters prize which appeared much earlier in the late 1990s is the inclusion of compression problems in an extended Turing test or by tests which are completely derived from Kolmogorov complexity
Other related tests in this line are presented by HernandezOrallo and Dowe

Algorithmic IQ or AIQ for short is an attempt to convert the theoretical Universal Intelligence Measure from Legg and Hutter (based on Solomonoffs theory of inductive inference
Two major advantages of some of these tests are their applicability to nonhuman intelligences and their absence of a requirement for human testers

 Ebert test 

The Turing test inspired the Ebert test proposed in 2011 by film critic Roger Ebert which is a test whether a computerbased Speech synthesis
 Social Turing Game 
Taking advantage of Large language model
 Conferences 

 Turing Colloquium 
1990 marked the fortieth anniversary of the first publication of Turings "Computing Machinery and Intelligence" paper and saw renewed interest in the test Two significant events occurred in that year: the first was the Turing Colloquium which was held at the University of Sussex in April and brought together academics and researchers from a wide variety of disciplines to discuss the Turing test in terms of its past present and future; the second was the formation of the annual Loebner Prize competition

Blay Whitby lists four major turning points in the history of the Turing test&nbsp;– the publication of "Computing Machinery and Intelligence" in 1950 the announcement of Joseph Weizenbaums ELIZA in 1966 Kenneth Colbys creation of PARRY which was first described in 1972 and the Turing Colloquium in 1990

 2005 Colloquium on Conversational Systems 

In November 2005 the University of Surrey hosted an inaugural oneday meeting of artificial conversational entity developers<ref>
citation

</ref>
attended by winners of practical Turing tests in the Loebner Prize: Robby Garner Richard Wallace (scientist)
 2008 AISB Symposium 

In parallel to the 2008 Loebner Prize held at the University of Reading<ref>
citation
    
</ref>
the Society for the Study of Artificial Intelligence and the Simulation of Behaviour (AISB) hosted a oneday symposium to discuss the Turing test organised by John Barnden Mark Bishop Huma Shah and Kevin Warwick<ref>
citation
      
</ref>
The speakers included the Royal Institutions Director Susan Greenfield Baroness Greenfield
 The Alan Turing Year and Turing100 in 2012 

Throughout 2012 a number of major events took place to celebrate Turings life and scientific impact The Turing100 group supported these events and also organised a special Turing test event in Bletchley Park on 23 June 2012 to celebrate the 100th anniversary of Turings birth

 See also 

 Natural language processing
 Artificial intelligence in fiction
 Blindsight
 Causality
 Chatbot
 ChatGPT
 Computer game bot Turing Test
 Dead Internet theory
 Explanation
 Explanatory gap
 Functionalism (philosophy of mind) Graphics Turing Test
 Ex Machina (film) Hard problem of consciousness
 List of things named after Alan Turing
 Mark V Shaney (Usenet bot)
 Mindbody problem
 Mirror neuron
 Philosophical zombie
 Problem of other minds
 Reverse engineering
 Sentience
 Simulated reality
 Social bot
 Technological singularity
 Theory of mind
 Uncanny valley
 VoightKampff machine (fictitious Turing test from Blade Runner)
 Winograd Schema Challenge
 SHRDLU


 Notes 


 References 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 citation
                       Reprinted in 

 citation


 citation



  Page numbers above refer to a standard pdf print of the article See also Searles https://webarchiveorg/web/20010221025515/http://wwwbbsonlineorg/Preprints/OldArchive/bbssearle2html original draft
 Citation



 Citation



 Citation



 Citation
           

 
 
  (reprinted in The Turing Test: The Elusive Standard of Artificial Intelligence edited by James H Moor Kluwer Academic 2003) 
 
 
 
  (reprinted in The Turing Test: The Elusive Standard of Artificial Intelligence edited by James H Moor Kluwer Academic 2003) 
 
 
 
 
 
 


 Further reading 

 
 Gary Marcus 
 Kevin Warwick

 External links 


 http://wwwturingtestoperacom The Turing Test – an Opera by Julian Wagstaff
 
 http://wwwrmcyberneticscom/science/cybernetics/ai_turing_testhtm The Turing Test – How accurate could the Turing test really be?
 
 https://webarchiveorg/web/20050512232753/http://crlucsdedu/~saygin/papers/MMTTpdf Turing Test: 50 Years Later reviews a halfcentury of work on the Turing Test from the vantage point of 2000
 http://wwwlongbetsorg/1 Bet between Kapor and Kurzweil including detailed justifications of their respective positions
 http://wwwsussexacuk/Users/blayw/tthtml Why The Turing Test is AIs Biggest Blind Alley by Blay Witby
 http://wwwjabberwackycom/ Jabberwackycom  An AI chatterbot that learns from and imitates humans
 New York Times essays on machine intelligence https://webarchiveorg/web/20040816143151/http://wwwrcirutgersedu/~cfs/472_html/Intro/NYT_Intro/History/MachineIntelligence2html part 1 and https://webarchiveorg/web/20040816143151/http://wwwrcirutgersedu/~cfs/472_html/Intro/NYT_Intro/History/MachineIntelligence2html part 2
 
 https://webarchiveorg/web/20091018043414/http://csunpluggedorg/turingtest Computer Science Unplugged teaching activity for the Turing test
 n:Computer professionals celebrate 10th birthday of ALICE





