

Monochrome photography is one of the earliest styles of photography and dates back to the 1800s Monochrome photography is also a popular technique among astrophotographers This is due to the omission of the Bayer filter a colour filter array that sits in front of the CMOS or CCD sensor allowing for a single sensor to produce a colour image

 Sensor design 
Colour cameras produce colour images using a Bayer filterFile:Bayer_pattern_on_sensorsvgMany objects in deep space are made up of hydrogen oxygen and sulphur These elements emit light in the red blue and red/orange spectrum respectively

When imaging an object rich in Hydrogen the object will primarily emit light in the hydrogenalpha/red wavelengths In this scenario the Bayer matrix will only allow 25% off the incoming light from the nebula to reach the sensor as only 25% of the matrix area will allow red light to pass through
File:Bayer_pattern_on_sensor_profilesvgA monochromatic sensor does not have a Bayer matrix This means the entire sensor can be utilised to capture specific wavelengths using specialised colour filters known as narrowband filters Many nebulae are made up of hydrogen oxygen and sulphur These nebulae emit light in red blue and orange wavelengths respectively A narrowband filter can be used for each colour to produce three discrete monochrome images These images can then be combined to produce a colour image

 Advantages 
Monochrome astrophotography has gained its popularity as a method of combating the effects of modern lightpollution The Bayer matrix in a traditional sensor will limit the available sensor area capable of collecting light from deep space objects to approximately 25% The remaining 75% however is still capable of collecting light often in the form of surrounding light pollution This can adversely affect the signaltonoise ratio

Removing the Bayer matrix means a narrowband filter can be used to only allow specific wavelengths of light to reach the sensor This has the benefit of utilising the entire sensor area to maximise the amount of light collected whilst also rejecting sources of external light pollution vastly improving the Signaltonoise ratio (imaging)
 Monochrome image processing 
Colour images in typical cameras are made by combining data from red green and blue pixels In order to produce a colour image using a monochrome sensor three monochrome images must be produced and combined to produce a colour image The three monochrome images are mapped to the respective red green and blue channels In the case of astrophotography this can vary to some degree although a common colour palette is the Hubble palette often known as "SHO" In the Hubble pallet Sulphur is mapped to the red channel hydrogenalpha signals are mapped to green and oxygen is mapped to blue

Monochrome astrophotography also requires a greater number of calibration frames Calibration frames are used capture artefacts and dust on the image sensor and filter and light gradients due to internal reflections in the optical train These can then be removed from the final image Monochrome imaging requires the use of three individual filters to produce a colour image This means three sets of calibration frames must be generated and applied during the image processing stage This therefore increases the amount of images that need to be stored requiring greater amounts of storage space

Monochrome photography also requires additional equipment Due to the requirement of multiple filters amateur astrophotographers often use an electronic filter wheel This allows multiple filters to be installed and a computer can be used to control the wheel and change filters throughout the night 

 References 


