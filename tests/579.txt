





Infobox software


LaMDA (Language Model for Dialogue Applications) is a family of conversational large language models developed by Google Originally developed and introduced as Meena in 2020 the firstgeneration LaMDA was announced during the 2021 Google I/O keynote while the second generation was announced the following year In June 2022 LaMDA gained widespread attention when Google Engineering technologist
 History 

 Background 
On January 28 2020 Google unveiled Meena a neural networkpowered chatbot with 26&nbsp;billion parameters which Google claimed to be superior to all other existing chatbots The company previously hired computer scientist Ray Kurzweil in 2012 to develop multiple chatbots for the company including one named Danielle The Google Brain research team who developed Meena hoped to release the chatbot to the public in a limited capacity but corporate executives refused on the grounds that Meena violated Googles "AI principles around safety and fairness" Meena was later renamed LaMDA as its data and computing power increased and the Google Brain team again sought to deploy the software to the Google Assistant the companys virtual assistant software in addition to opening it up to a public demo Both requests were once again denied by company leadership This eventually led LaMDAs two lead researchers Daniel De Freitas and Noam Shazeer to depart the company in frustration

 First generation 
Google announced the LaMDA conversational large language model during the Google I/O keynote on May 18 2021 powered by artificial intelligence The acronym stands for "Language Model for Dialogue Applications" Built on the seq2seq architecture Transformer (machine learning model)
 Second generation 
On May 11 2022 Google unveiled LaMDA 2 the successor to LaMDA during the 2022 Google I/O keynote The new incarnation of the model draws examples of text from numerous sources using it to formulate unique "natural conversations" on topics that it may not have been trained to respond to

 Sentience claims 
File:Turing test diagrampngOn June 11 2022 The Washington Post reported that Google Engineering technologist
Lemoines claims were widely pushed back by the scientific community Many experts ridiculed the idea that a language model could be selfaware including former New York University psychology professor Gary Marcus David Pfau of Google sister company DeepMind Erik Brynjolfsson of the Institute for HumanCentered Artificial Intelligence at Stanford University and University of Surrey professor Adrian Hilton Yann LeCun who leads Meta Platforms AI research team stated that neural networks such as LaMDA were "not powerful enough to attain true intelligence" University of California Santa Cruz professor Max Kreminski noted that LaMDAs architecture did not "support some key capabilities of humanlike consciousness" and that its neural network weights were "frozen" assuming it was a typical large language model IBM Watson lead developer David Ferrucci compared how LaMDA appeared to be human in the same way Watson did when it was first introduced Former Google AI ethicist Timnit Gebru called Lemoine a victim of a "hype cycle" initiated by researchers and the media Lemoines claims have also generated discussion on whether the Turing test remained useful to AI effect
 Products 

 AI Test Kitchen 
With the unveiling of LaMDA 2 in May 2022 Google also launched the AI Test Kitchen a mobile application for the Android (operating system)
 Bard 

On February 6 2023 Google announced Bard a conversational AI chatbot powered by LaMDA in response to the unexpected popularity of OpenAIs ChatGPT chatbot Google positions the chatbot as a "collaborative AI service" rather than a search engine Bard became available for early access on March 21

 Other products 
In addition to Bard Pichai also unveiled the companys Generative Language API an application programming interface also based on LaMDA which he announced would be opened up to thirdparty developers in March 2023

 Method 

LaMDA uses a decoderonly transformer language model It is pretrained on a text corpus that includes both documents and dialogs consisting of 156&nbsp;trillion words and is then trained with finetuning data generated by manually annotated responses for sensibleness interestingness and safety Tests by Google indicated that LaMDA surpassed human responses in the area of interestingness The LaMDA transformer model and an external information retrieval system interact to improve the accuracy of facts provided to the user

Three different models were tested with the largest having 137&nbsp;billion nonembedding parameters:

! Parameters !! Layers !! Units (d<sub>model</sub>) !! Heads

 See also 
 BERT (language model)
 Chinese room
 Ethics of artificial intelligence
 Natural language processing
 PaLM
 Philosophy of artificial intelligence
 Prompt engineering

 References 

 General

 


 Citations 
reflist
<! BACKGROUND >









<! FIRST GENERATION>











<! SECOND GENERATION >



<! SENTIENCE CLAIMS >

































<! AI TEST KITCHEN >



















<! BARD >

















<! METHOD >





 External links 
 https://bloggoogle/technology/ai/lamda/ Press release





