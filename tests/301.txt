

Singularitarianism is a Social movement
Singularitarians are distinguished from other futurists who speculate on a technological singularity by their belief that the singularity is not only possible but desirable if guided prudently Accordingly they may sometimes dedicate their lives to acting in ways they believe will contribute to its rapid yet safe realization

Time (magazine)
Definition
The term "Singularitarian" was originally defined by Extropianism
Singularitarianism can also be thought of as an orientation or an outlook that prefers the enhancement of human intelligence as a specific transhumanism
Inventor and futurist Ray Kurzweil author of the 2005 book The Singularity Is Near
History
An early singularitarian articulation that history is making progress toward a point of superhuman intelligence is found in Hegels work The Phenomenology of Spirit In 1993 mathematician computer scientist and science fiction author Vernor Vinge hypothesized that the moment might come when technology will allow "creation of entities with greater than human intelligence" and used the term "the Singularity" to describe this moment He suggested that the singularity may pose an existential risk for humanity and that it could happen through one of four means:

The development of computers that are "awake" and superhumanly intelligent 
Large computer networks (and their associated users) may "wake up" as a superhumanly intelligent entity
Computer/human interfaces may become so intimate that users may reasonably be considered superhumanly intelligent
Biological science may find ways to improve upon the natural human intellect 

Singularitarianism coalesced into a coherent ideology in 2000 when artificial intelligence (AI) researcher Eliezer Yudkowsky wrote The Singularitarian Principles in which he stated that a Singularitarian believes that the singularity is a secular nonmystical event which is possible and beneficial to the world and is worked towards by its adherents Yudkowskys conceptualization of singularity offered a broad definition developed to be inclusive of various interpretations There are theorists such as Michael Anissimov who argued for a strict definition one that refers only to the advocacy of the development of posthuman (greater than human) intelligence 

In June 2000 Yudkowsky with the support of Internet entrepreneurs Brian Atkins and Sabine Atkins founded the Machine Intelligence Research Institute to work towards the creation of selfimproving Friendly artificial intelligence
Many people believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy Although the exact numbers are hard to quantify Singularitarianism is a small movement which includes transhumanism


With the support of NASA Google and a broad range of technology forecasting
In July 2009 many prominent Singularitarians participated in a conference organized by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become selfsufficient and able to make their own decisions They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy and to what degree they could use such abilities to possibly pose any threat or hazard (ie cybernetic revolt) They noted that some machines have acquired various forms of semiautonomy including being able to find power sources on their own and being able to independently choose targets to attack with weapons They warned that some computer viruses can evade elimination and have achieved "cockroach intelligence" They asserted that selfawareness as depicted in science fiction is probably unlikely but that there were other potential hazards and pitfalls Some experts and academics have questioned the use of military robot
Reception
There are several objections to Kurzweils singularitarianism and these even include criticisms from optimists within the AI field For instance Pulitzer Prize winning author Douglas Hofstadter argued that Kurzweils predicted achievement of humanlevel AI by 2045 is not viable Even Gordon Moore who is credited for introducing the Moores law

Kurzweil rejects this categorization stating that his predictions about the singularity are driven by the data that increases in computational technology have been exponential in the past He also claimed that critics who challenge his view mistakenly take an intuitive linear view of technological advancement

See also
 Artificial general intelligence
 Eschatology
 Existential risk from artificial general intelligence
 Global brain
 Intelligence explosion
 Outline of transhumanism
 Postscarcity economy
 Technological utopianism

References


 External links 
 http://wwwnickbostromcom/ethics/aihtml Ethical Issues in Advanced Artificial Intelligence by Nick Bostrom 2003
 https://spectrumieeeorg/theconsciousnessconundrum "The Consciousness Conundrum" a criticism of singularitarians by John Horgan (American journalist)
