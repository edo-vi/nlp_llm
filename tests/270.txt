


Artificial intelligence and moral enhancement involves the application of artificial intelligence to the enhancement of moral reasoning and the acceleration of moral progress

Artificial moral reasoning


With respect to moral reasoning some consider humans to be suboptimal information processors moral judges and moral agents Due to stress or time constraints people often fail to consider all the relevant factors and information necessary to make wellreasoned Moral reasoning
With the rise of artificial intelligence Moral agencyArtificial moral agents
Ideal observer theory


The classical ideal observer theory is a metaethics
Adam Smith and David Hume espoused versions of the ideal observer theory and Roderick Firth provided a more sophisticated and modern version An analogous idea in law is the reasonable person criterion

Today artificial intelligence systems are capable of providing or assisting in moral decisions stating what we ought to morally do if we want to comply with certain moral principles These systems can enable humans to make (nearly) optimal moral choices that we do not or cannot usually perform because of lack of necessary mental resources or time constraints

Artificial moral advisors can be compared and contrasted with ideal observer theory
Users can provide varying configurations and settings to instruct these systems and this allows these systems to be relativist Relativist artificial moral advisors would equip humans to be better moral judges and would respect their autonomy as both moral judges and moral agents For these reasons and because artificial moral advisors would be disinterested dispassionate consistent relational dispositional empirical and objectivist relativist artificial moral advisors could be preferable to Universality (philosophy)
Exhaustive versus auxiliary enhancement
Exhaustive enhancement involves scenarios where human moral decisionmaking is supplanted left entirely to machines Some proponents consider machines as being morally superior to humans and that just doing as the machines say would constitute moral improvement

Opponents of exhaustive enhancement list five main concerns: (1) the existence of Pluralism_(political_philosophy)
Dependence on artificial intelligence systems to perform moral reasoning would not only neglect the cultivation of moral excellence but actively undermine it exposing people to risks of disengagement of atrophy of human faculties and of moral manipulation at the hands of the systems or their creators

Auxiliary enhancement addresses these concerns and involves scenarios where machines augment or supplement human decisionmaking Artificial intelligence assistants would be tools to help people to clarify and keep track of their moral commitments and contexts while providing accompanying explanations arguments and Justification (epistemology)
Some proponents of auxiliary enhancement also support Educational technology
Pluralism
Moral agencyArtificial moral agents
Beyond matching their usersâ€™ moral commitments Moral agencyArtificial moral agents
See also
 AI alignment
 Artificial intelligence
 Automated decisionmaking
 Decision support system
 Intelligent tutoring system
 Legal informatics
 Machine ethics
 Moral reasoning
 Multiagent systems
 Project Debater
 Superintelligence

References


