File:Child interacts with an ArtBot at 2011 showjpgMany scholars believe that advances in artificial intelligence or AI will eventually lead to a semiapocalyptic postscarcity economy where intelligent machines can outperform humans in nearly if not every domain The questions of what such a world might look like and whether specific scenarios constitute utopias or dystopias are the subject of active debate

 Background 


Most scientists believe that AI research will at some point lead to the creation of machines that are as intelligent or more intelligent than human beings in every domain of interest There is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains; therefore superintelligence is physically possible In addition to potential algorithmic improvements over human brains a digital brain can be many orders of magnitude larger and faster than a human brain which was constrained in size by evolution to be small enough to fit through a birth canal While there is no consensus on when artificial intelligence will outperform humans many scholars argue that whenever it does happen the introduction of a second species of intelligent life onto the planet will have farreaching implications Scholars often disagree with one another both about what types of postAI scenarios are most likely and about what types of postAI scenarios would be most desirable Finally some dissenters argue that AI will never become as intelligent as humans for example because the human race will already likely have destroyed itself before research has time to advance sufficiently to create artificial general intelligence

 Postulates: robot labor and postscarcity economy 

All of the following "AI aftermath scenarios" of the aftermath of arbitrarilyadvanced AI development are crucially dependent on two intertwined theses The first thesis is that at some point in the future some kind of economic growth will continue until a "postscarcity" economy is reached that could unless extremely hyperconcentrated effortlessly provide an extremely comfortable standard of living for a population equaling or within reason exceeding the current human population without even requiring the bulk of the population to participate in the workforce This economic growth could come from the continuation of existing growth trends and the refinement of existing technologies or through future breakthroughs in emerging technologies such as nanotechnology and automation through robotics and futuristic advanced artificial intelligence The second thesis is that advances in artificial intelligence will render humans unnecessary for the functioning of the economy: human labor declines in relative economic value if robots are easier to cheaply massproduce then humans more customizable than humans and if they become more intelligent and capable than humans

 Cosmic endowment and limits to growth 
The Universe may be spatially infinite; however the accessible Universe is bounded by the Cosmological horizonEvent horizon
 AI aftermath scenarios 
 Libertarianism 
Libertarian transhumanismproperty rights Because industrial productivity is no longer gated by scarce human labor the value of land skyrockets compared to the price of goods; even remaining "LudditeModern usage


Such decentralized scenarios may be unstable in the long run as the greediest elements of the super intelligent classes would have both the means and the motive to usurp the property of the unenhanced classes Even if the mechanisms for ensuring legal property rights are both unbreakable and loopholefree there may still be an everpresent danger of humans and cyborgs being "tricked" by the cleverest of the superintelligent machines into unwittingly signing over their own property Suffering may be widespread as sentient beings without property may die and no mechanism prevents a being from reproducing up until the limits of his own inheritable resources resulting in a multitude of that beings descendants scrabbling out an existence of minimal sustenance



Benevolent dictator
File:2010 Utopien arche04jpg

In this scenario postulate that a superintelligent artificial intelligence takes control of society but acts in a beneficial way Its programmers despite being on a deadline solved quasiphilosophical problems that had seemed to some intractable and created an AI with the following goal: to use its superintelligence to figure out what human utopia looks like by analyzing human behavior human brains and human genes; and then to implement that utopia The AI arrives at a subtle and complex definition of human flourishing Valuing diversity and recognizing that different people have different preferences the AI divides Earth into different sectors Harming others making weapons evading surveillance or trying to create a rival superintelligence are globally banned; apart from that each sector is free to make its own laws; for example a religious person might choose to live in the "pious sector" corresponding to his religion where the appropriate religious rules are strictly enforced In all sectors disease poverty crime hangovers addiction and all other involuntary suffering have been eliminated Many sectors boast advanced architecture and spectacle that "make typical scifi visions pale in comparison"



Still many people are dissatisfied Tegmark writes Humans have no freedom in shaping their collective destiny Some want the freedom to have as many children as they want Others resent surveillance by the AI or chafe at bans on weaponry and on creating further superintelligence machines Others may come to regret the choices they have made or find their lives feel hollow and superficial

Bostrom argues that an AIs code of ethics should ideally improve in certain ways on current norms of moral behavior in the same way that we regard current morality to be superior to the morality of earlier eras of slavery In contrast Ernest Davis of New York University this approach is too dangerous stating "I feel safer in the hands of a superintelligence who is guided by 2014 morality or for that matter by 1700 morality than in the hands of one that decides to consider the question for itself"

Gatekeeper AI
In "Gatekeeper" AI scenarios the AI can act to prevent rival superintelligences from being created but otherwise errs on the side of allowing humans to create their own destiny In a third scenario a superintelligent "Protector" AI gives humans the illusion of control by hiding or erasing all knowledge of its existence but works behind the scenes to guarantee positive outcomes In all three scenarios while humanity gains more control (or at least the illusion of control) humanity ends up progressing more slowly than it would if the AI were unrestricted in its willingness to rain down all the benefits of its advanced technology on the human race

Boxed AI
File:Frederick Stuart Church  Opened up a Pandoras boxjpg


The AI Box scenario postulates that a superintelligent AI can be "confined to a box" and its actions can be restricted by human gatekeepers; the humans in charge would try to take advantage of some of the AIs scientific breakthroughs or reasoning abilities without allowing the AI to take over the world Successful gatekeeping may be difficult; the more intelligent the AI is the more likely the AI can find a clever way to use "social hacking" and convince the gatekeepers to let it escape or even to find an unforeseen physical method of escape

HumanAI merger
Kurzweil argues that in the future "There will be no distinction postSingularity between human and machine or between physical and virtual reality"

Human extinction


If a dominant superintelligent machine were to conclude that human survival is an unnecessary risk or a waste of resources the result would be human extinction This could occur if a machine programmed without respect for human values unexpectedly gains superintelligence through recursive selfimprovement or manages to escape from its containment in an AI Box scenario This could also occur if the first superintelligent AI was programmed with an incomplete or inaccurate understanding of human values either because the task of instilling the AI with human values was too difficult or impossible; due to a buggy initial implementation of the AI; or due to bugs accidentally being introduced either by its human programmers or by the selfimproving AI itself in the course of refining its code base Bostrom and others argue that human extinction is probably the "default path" that society is currently taking in the absence of substantial preparatory attention to AI safety The resultant AI might not be sentient and might place no value on sentient life; the resulting hollow world devoid of life might be like "a Disneyland without children"

Zoo
Jerry Kaplan author of Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence posits a scenario where humans are farmed or kept on a reserve just as humans preserve endangered species like chimpanzees Apple cofounder and AI skeptic Steve Wozniak stated in 2015 that robots taking over would actually "be good for the human race" on the grounds that he believes humans would become the robots pampered pets

 Alternatives to AI 
Some scholars doubt that "gamechanging" superintelligent machines will ever come to pass Gordon Bell of Microsoft Research has stated "the population will destroy itself before the technological singularity" Gordon Moore discoverer of the eponymous Moores law stated "I am a skeptic I dont believe this kind of thing is likely to happen at least for a long time And I dont know why I feel that way" Evolutionary psychologist Steven Pinker stated "The fact that you can visualize a future in your imagination is not evidence that it is likely or even possible"

Bill Joy of Sun Microsystems in his April 2000 essay Why the Future Doesnt Need Us has advocated for global "voluntary relinquishment" of artificial general intelligence and other risky technologies Most experts believe relinquishment is extremely unlikely AI skeptic Oren Etzioni has stated that researchers and scientists have no choice but to push forward with AI developments: "China says they want to be an AI leader Putin has said the same thing So the global race is on"

 References 


See also
 Existential risk from artificial general intelligence

